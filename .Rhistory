title = "California City Temperatures",
subtitle = paste("Date:", Sys.Date())
) +
theme_minimal()
library(rnaturalearth)
library(rnaturalearthdata)
ca <- ne_states(country = "United States of America", returnclass = "sf") %>%
filter(name == "California")
ggplot() +
geom_sf(data = ca, fill = "gray95", color = "gray60") +
geom_sf(data = weather_sf, aes(color = temp_max), size = 6) +
geom_sf_label(data = weather_sf, aes(label = city), nudge_y = 0.5, size = 2.5) +
scale_color_viridis_c(option = "plasma", name = "High Temp (°F)") +
labs(
title = "California City Temperatures",
subtitle = paste("Date:", Sys.Date())
) +
theme_minimal()
#sf_map <- function(cities)
cities <- c("San Luis Obispo", "Santa Barbara", "San Francisco")
# Function to get coordinates + weather summary
get_city_weather <- function(city, date = Sys.Date()) {
geo_url <- paste0(
"http://api.openweathermap.org/geo/1.0/direct?",
"q=", URLencode(city),
"&limit=1&appid=", api_key
)
geo_response <- GET(geo_url)
if (status_code(geo_response) == 200) {
geo_data <- fromJSON(content(geo_response, as = "text"), flatten = TRUE)
if (length(geo_data) == 0) return(NULL)
lat <- geo_data$lat
lon <- geo_data$lon
weather_url <- paste0(
"https://api.openweathermap.org/data/3.0/onecall/day_summary?",
"lat=", lat,
"&lon=", lon,
"&date=", format(date, "%Y-%m-%d"),
"&appid=", api_key,
"&units=imperial"
)
weather_response <- GET(weather_url)
if (status_code(weather_response) == 200) {
weather_data <- fromJSON(content(weather_response, as = "text"), flatten = TRUE)
tibble(
city = city,
date = date,
lat = lat,
lon = lon,
temp_max = weather_data$temperature$max,
temp_min = weather_data$temperature$min
)
} else return(NULL)
} else return(NULL)
}
# Fetch for all cities
weather_df <- bind_rows(lapply(cities, get_city_weather))
View(weather_response)
weather_response[["content"]]
geocode <- function(city){
geo_url <- paste0(
"http://api.openweathermap.org/geo/1.0/direct?",
"q=", URLencode(city),
"&limit=1&appid=", api_key
)
geo_response <- GET(geo_url)
if (status_code(geo_response) == 200) {
geo_data <- fromJSON(content(geo_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
# Step 1c: Assess if the output has 0 length, meaning no result. If so, stop and display an error message.
if (length(geo_data) == 0) {
stop("City not found. Please check the city name.")
}
# Step 1d: Assign latitude and longitude to variables, and use round() to clip it down to 2 decimal places.
lat <- round(geo_data$lat, digits = 2)
lon <- round(geo_data$lon, digits = 2)
# Optional: Print a string displaying the city name and latitude / longitude.
return(cat("Coordinates for", city, "-> Latitude:", lat, "Longitude:", lon, "\n"))
}
}
geocode("Ames")
geocode("Story City")
geocode("Story City, IA, USA")
geocode("Ames, IA, USA")
prev_weather("Ames, IA, USA", 4)
df4 <- prev_weather("Ames, IA, USA") |>  mutate(date = as.Date(date))
library(httr2)
library(tibble)
library(jsonlite)
library(httr)
library(lubridate)
library(ggplot2)
library(dplyr)
library(dotenv)
library(sf)
getwd()
dotenv::load_dot_env(file = ".Renviron.txt")
api_key <- Sys.getenv("API_KEY")
city_name <- "San Luis Obispo"
current_weather_url <- "https://api.openweathermap.org/data/2.5/weather"
current_query <- list(q = city_name, appid = api_key, units = "imperial")
response <- GET(current_weather_url, query = current_query)
http_type(response)
if (status_code(response) == 200) {
# Parse and flatten JSON
content_json <- content(response, as = "text", encoding = "UTF-8")
parsed <- fromJSON(content_json, flatten = TRUE)
# Convert to data frame directly
currweather <- as.data.frame(parsed)
print(names(currweather))
} else {
cat("Failed. Status code:", status_code(response), "\n")
}
json_result <- content(response, as = "parsed")
class(json_result)
print(currweather)
geo_url <- paste0(
"http://api.openweathermap.org/geo/1.0/direct?",
"q=", URLencode(city_name),
"&limit=1&appid=", api_key
)
numdays <- 5
geo_response <- GET(geo_url)
if (status_code(geo_response) == 200) {
geo_data <- fromJSON(content(geo_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
# Step 1c: Assess if the output has 0 length, meaning no result. If so, stop and display an error message.
if (length(geo_data) == 0) {
stop("City not found. Please check the city name.")
}
# Step 1d: Assign latitude and longitude to variables, and use round() to clip it down to 2 decimal places.
lat <- round(geo_data$lat, digits = 2)
lon <- round(geo_data$lon, digits = 2)
# Optional: Print a string displaying the city name and latitude / longitude.
cat("Coordinates for", city_name, "-> Latitude:", lat, "Longitude:", lon, "\n")
# Step 2: Use the One Call API to get the past 5 days of weather data
# Step 2a: Define the date range (modify this as needed)
date_range <- as.character(lubridate::today() - days(1:numdays)) # past 5 days turn into argumen to pass into function
# Step 2b: Initialize data frame to hold the outputs. "p5weather" for past 5 weather.
p5weather <- data.frame()
# Step 2c: Loop over dates and make an API call for each day. For every date in the date vector, supply latitude, longitude, the different date, API key, and provide unit preference.
for (date in date_range) {
weather_url <- paste0(
"https://api.openweathermap.org/data/3.0/onecall/day_summary?",
"lat=", lat,
"&lon=", lon,
"&date=", date,
"&appid=", api_key,
"&units=imperial"
)
# Step 2d: Make the API call using the different weather_url queries for each date. Store these in weather_response
weather_response <- GET(weather_url)
# Step 2e: Use logic to evaluate the response and use fromJSON() to get the content from the JSON output and use "flatten = TRUE" to unnest the data.
if (status_code(weather_response) == 200) {
weather_parsed <- jsonlite::fromJSON(content(weather_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
# Step 2f: Use the output for each day and assign it into a data frame.
daily_df <- as.data.frame(weather_parsed)
# Step 2g: Add date and city name columns ## USE MUTATE
daily_df$city <- city_name
daily_df$date <- date
# Step 2h: Use bind_rows to add all the rows to the p5weather data frame.
p5weather <- bind_rows(p5weather, daily_df)
} else {
# Step 2i: Use logic (else) to print an error message for when weather data is not obtained.
warning(paste("Failed to get weather for", date, "-", status_code(weather_response)))
}
}
print(p5weather)
} else {
stop("Geocoding failed. Check your API key or city name.")
}
prev_weather <- function(city, numdays){
geo_url <- paste0(
"http://api.openweathermap.org/geo/1.0/direct?",
"q=", URLencode(city),
"&limit=1&appid=", api_key
)
geo_response <- GET(geo_url)
if (status_code(geo_response) == 200) {
geo_data <- fromJSON(content(geo_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
# Step 1c: Assess if the output has 0 length, meaning no result. If so, stop and display an error message.
if (length(geo_data) == 0) {
stop("City not found. Please check the city name.")
}
# Step 1d: Assign latitude and longitude to variables, and use round() to clip it down to 2 decimal places.
lat <- round(geo_data$lat, digits = 2)
lon <- round(geo_data$lon, digits = 2)
# Optional: Print a string displaying the city name and latitude / longitude.
cat("Coordinates for", city, "-> Latitude:", lat, "Longitude:", lon, "\n")
# Step 2: Use the One Call API to get the past 5 days of weather data
# Step 2a: Define the date range (modify this as needed)
date_range <- as.character(lubridate::today() - days(1:numdays)) # past 5 days turn into argumen to pass into function
# Step 2b: Initialize data frame to hold the outputs. "p5weather" for past 5 weather.
p5weather <- data.frame()
# Step 2c: Loop over dates and make an API call for each day. For every date in the date vector, supply latitude, longitude, the different date, API key, and provide unit preference.
for (date in date_range) {
weather_url <- paste0(
"https://api.openweathermap.org/data/3.0/onecall/day_summary?",
"lat=", lat,
"&lon=", lon,
"&date=", date,
"&appid=", api_key,
"&units=imperial"
)
# Step 2d: Make the API call using the different weather_url queries for each date. Store these in weather_response
weather_response <- GET(weather_url)
# Step 2e: Use logic to evaluate the response and use fromJSON() to get the content from the JSON output and use "flatten = TRUE" to unnest the data.
if (status_code(weather_response) == 200) {
weather_parsed <- jsonlite::fromJSON(content(weather_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
# Step 2f: Use the output for each day and assign it into a data frame.
daily_df <- as.data.frame(weather_parsed)
# Step 2g: Add date and city name columns ## USE MUTATE
daily_df$city <- city
daily_df$date <- date
# Step 2h: Use bind_rows to add all the rows to the p5weather data frame.
p5weather <- bind_rows(p5weather, daily_df)
} else {
# Step 2i: Use logic (else) to print an error message for when weather data is not obtained.
warning(paste("Failed to get weather for", date, "-", status_code(weather_response)))
}
}
return(p5weather)
} else {
stop("Geocoding failed. Check your API key or city name.")
}
}
prev_weather("Ames, IA, USA", 4)
df4 <- prev_weather("Ames, IA, USA") |>  mutate(date = as.Date(date))
ggplot(df4, aes(x = date)) +
geom_line(aes(y = temperature.max, color = "High"), size = 1.2) +
geom_line(aes(y = temperature.min, color = "Low"), size = 1.2) +
scale_color_manual(values = c("High" = "red", "Low" = "blue")) +
labs(
title = paste("High and Low Temperatures in", unique(df4$city)),
x = "Date",
y = "Temperature (°F)",
color = "Temperature Type"
) +
theme_minimal(base_size = 14)
View(df4)
df4 <- prev_weather("Ames, IA, USA") |>  mutate(date = as.Date(date))
ggplot(df4, aes(x = date)) +
geom_line(aes(y = temperature.max, color = "High"), size = 1.2) +
geom_line(aes(y = temperature.min, color = "Low"), size = 1.2) +
scale_color_manual(values = c("High" = "red", "Low" = "blue")) +
labs(
title = paste("High and Low Temperatures in", unique(df4$city)),
x = "Date",
y = "Temperature (°F)",
color = "Temperature Type"
) +
theme_minimal(base_size = 14)
df4 <- prev_weather("Ames, IA, USA", 4) |>  mutate(date = as.Date(date))
ggplot(df4, aes(x = date)) +
geom_line(aes(y = temperature.max, color = "High"), size = 1.2) +
geom_line(aes(y = temperature.min, color = "Low"), size = 1.2) +
scale_color_manual(values = c("High" = "red", "Low" = "blue")) +
labs(
title = paste("High and Low Temperatures in", unique(df4$city)),
x = "Date",
y = "Temperature (°F)",
color = "Temperature Type"
) +
theme_minimal(base_size = 14)
library(rnaturalearth)
library(rnaturalearthdata)
ca <- ne_states(country = "United States of America", returnclass = "sf") %>%
filter(name == "California")
ggplot() +
geom_sf(data = ca, fill = "gray95", color = "gray60") +
geom_sf(data = weather_sf, aes(fill = temp_max), size = 6) +
geom_sf_label(data = weather_sf, aes(label = city), nudge_y = 0.5, size = 2.5) +
scale_color_viridis_c(option = "plasma", name = "High Temp (°F)") +
labs(
title = "California City Temperatures",
subtitle = paste("Date:", Sys.Date())
) +
theme_minimal()
library(rnaturalearth)
library(rnaturalearthdata)
ca <- ne_states(country = "United States of America", returnclass = "sf") %>%
filter(name == "California")
ggplot() +
geom_sf(data = ca, fill = "gray95", color = "gray60") +
geom_sf(data = weather_sf, aes(color = temp_max), size = 6) +
geom_sf_label(data = weather_sf, aes(label = city), nudge_y = 0.5, size = 2.5) +
scale_color_viridis_c(option = "plasma", name = "High Temp (°F)") +
labs(
title = "California City Temperatures",
subtitle = paste("Date:", Sys.Date())
) +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
#| echo: false
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(rlang)
library(purrr)
## Creation of URL
team_name <- "was"
year <- 2023
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
## Special Note 1: Maybe Optional (Further Research is needed on its relevance)
# request_details <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
# response <- GET(url, user_agent(request_details),timeout(20))
webpage <- generic_url %>%
rvest::read_html()
View(webpage)
view(webpage)
knitr::opts_chunk$set(echo = TRUE)
#| echo: false
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(rlang)
library(purrr)
## Creation of URL
team_name <- "was"
year <- 2023
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
## Special Note 1: Maybe Optional (Further Research is needed on its relevance)
# request_details <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
# response <- GET(url, user_agent(request_details),timeout(20))
webpage <- generic_url %>%
rvest::read_html()
web_tables <- webpage %>%
rvest::html_table()
int_web_table <- web_tables %>%
purrr::pluck(2)
inital_col_names <- colnames(int_web_table)
first_row_names <- int_web_table[1,]
new_colnames <- paste(inital_col_names,first_row_names,sep="_") %>%
str_trim() %>%
str_to_lower()
new_colnames[6] <- "game_location"
new_colnames[21] <- "passing_yds_sk"
colnames(int_web_table) <- new_colnames
web_table1 <- int_web_table %>%
dplyr::slice(2:18)
web_table2 <- web_table1 %>%
mutate(
across(where(~ all(grepl("^\\s*-?\\d*\\.?\\d+\\s*$", .x))), ~ as.numeric(.)))
web_table3 <- web_table2  %>%
mutate(
score_rslt = as.factor(score_rslt),
game_location = case_when(
game_location == "@" ~ "away",
game_location == "" ~ "home",
TRUE ~ game_location
) %>%
as.factor()
)
web_table4 <- web_table3 |>
dplyr::rename_with(~ str_replace(., "^_", ""), .cols = starts_with("_"))
fn_year <- function(year){
team_name <- "was"
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
webpage <- generic_url %>%
rvest::read_html()
web_tables <- webpage %>%
rvest::html_table()
int_web_table <- web_tables %>%
purrr::pluck(2)
inital_col_names <- colnames(int_web_table)
first_row_names <- int_web_table[1,]
new_colnames <- paste(inital_col_names,first_row_names,sep="_") %>%
str_trim() %>%
str_to_lower()
new_colnames[6] <- "game_location"
new_colnames[21] <- "passing_yds_sk"
colnames(int_web_table) <- new_colnames
web_table1 <- int_web_table %>%
slice(2:18) |>
mutate(
across(where(~ all(grepl("^\\s*-?\\d*\\.?\\d+\\s*$", .x))), ~ as.numeric(.)))
web_table2 <- web_table1 |>
mutate(
score_rslt = as.factor(score_rslt),
game_location = case_when(
game_location == "@" ~ "away",
game_location == "" ~ "home",
TRUE ~ game_location
) %>%
as.factor()
)
web_table_3 <- web_table2 |>
rename_with(~ str_replace(., "^_", ""), .cols = starts_with("_"))
return(web_table_3)
}
head(fn_year(2022))
fn_team_year <- function(team_name, year){
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
webpage <- generic_url %>%
rvest::read_html()
web_tables <- webpage %>%
rvest::html_table()
int_web_table <- web_tables %>%
purrr::pluck(2)
inital_col_names <- colnames(int_web_table)
first_row_names <- int_web_table[1,]
new_colnames <- paste(inital_col_names,first_row_names,sep="_") %>%
str_trim() %>%
str_to_lower()
new_colnames[6] <- "game_location"
new_colnames[21] <- "passing_yds_sk"
colnames(int_web_table) <- new_colnames
web_table1 <- int_web_table %>%
slice(2:18) |>
mutate(
across(where(~ all(grepl("^\\s*-?\\d*\\.?\\d+\\s*$", .x))), ~ as.numeric(.)))
web_table2 <- web_table1 |>
mutate(
score_rslt = as.factor(score_rslt),
game_location = case_when(
game_location == "@" ~ "away",
game_location == "" ~ "home",
TRUE ~ game_location
) %>%
as.factor()
)
web_table_3 <- web_table2 |>
rename_with(~ str_replace(., "^_", ""), .cols = starts_with("_"))
return(web_table_3)
}
fn_year <- function(year){
team_name <- "was"
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
webpage <- generic_url %>%
rvest::read_html()
web_tables <- webpage %>%
rvest::html_table()
int_web_table <- web_tables %>%
purrr::pluck(2)
inital_col_names <- colnames(int_web_table)
first_row_names <- int_web_table[1,]
new_colnames <- paste(inital_col_names,first_row_names,sep="_") %>%
str_trim() %>%
str_to_lower()
new_colnames[6] <- "game_location"
new_colnames[21] <- "passing_yds_sk"
colnames(int_web_table) <- new_colnames
web_table1 <- int_web_table %>%
slice(2:18) |>
mutate(
across(where(~ all(grepl("^\\s*-?\\d*\\.?\\d+\\s*$", .x))), ~ as.numeric(.)))
web_table2 <- web_table1 |>
mutate(
score_rslt = as.factor(score_rslt),
game_location = case_when(
game_location == "@" ~ "away",
game_location == "" ~ "home",
TRUE ~ game_location
) %>%
as.factor()
)
web_table_rslt <- web_table2 |>
rename_with(~ str_replace(., "^_", ""), .cols = starts_with("_"))
return(web_table_rslt)
}
head(fn_year(2022))
fn_team_year <- function(team_name, year){
generic_url <- paste0("https://www.pro-football-reference.com/teams/",team_name,"/",year,".htm#all_games")
webpage <- generic_url %>%
rvest::read_html()
web_tables <- webpage %>%
rvest::html_table()
int_web_table <- web_tables %>%
purrr::pluck(2)
inital_col_names <- colnames(int_web_table)
first_row_names <- int_web_table[1,]
new_colnames <- paste(inital_col_names,first_row_names,sep="_") %>%
str_trim() %>%
str_to_lower()
new_colnames[6] <- "game_location"
new_colnames[21] <- "passing_yds_sk"
colnames(int_web_table) <- new_colnames
web_table1 <- int_web_table %>%
slice(2:18) |>
mutate(
across(where(~ all(grepl("^\\s*-?\\d*\\.?\\d+\\s*$", .x))), ~ as.numeric(.)))
web_table2 <- web_table1 |>
mutate(
score_rslt = as.factor(score_rslt),
game_location = case_when(
game_location == "@" ~ "away",
game_location == "" ~ "home",
TRUE ~ game_location
) %>%
as.factor()
)
web_table_rslt <- web_table2 |>
rename_with(~ str_replace(., "^_", ""), .cols = starts_with("_"))
return(web_table_rslt)
}
View(web_table4)
head(fn_team_year("sfo", 2024))
head(fn_team_year("sfo", 2024))
ggplot(df, aes(x = as.Date(date), y = score_pts)) +
geom_line(color = "steelblue", size = 1.2) +
geom_point(size = 3) +
labs(title = "Points Scored Over Time", x = "Date", y = "Points Scored") +
theme_minimal()
ggplot(fn_team_year("sfo", 2024), aes(x = as.Date(date), y = score_pts)) +
geom_line(color = "steelblue", size = 1.2) +
geom_point(size = 3) +
labs(title = "Points Scored Over Time", x = "Date", y = "Points Scored") +
theme_minimal()
ggplot(fn_team_year("sfo",2024), aes(x = game_location, y = score_pts, fill = game_location)) +
geom_boxplot() +
labs(title = "Points Scored: Home vs Away", x = "Location", y = "Points Scored") +
theme_minimal()
